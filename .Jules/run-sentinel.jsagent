#!/usr/bin/env node

/**
 * Sentinel Agent - Automated Hygiene and Conflict Resolution
 *
 * Mission:
 * Run a daily scan across all open pull requests and resolve mechanical merge conflicts automatically,
 * while leaving complex or semantic conflicts for Codex/human review.
 */

const fs = require('fs');
const path = require('path');
const { spawnSync } = require('child_process');
const https = require('https');

// --- Configuration ---
const GITHUB_TOKEN = process.env.GITHUB_TOKEN;
const [OWNER, REPO] = (process.env.GITHUB_REPOSITORY || 'goldshore/astro-goldshore').split('/');
const ARGS = process.argv.slice(2);
const MODE = ARGS.includes('--mode=sweep') ? 'SWEEP' : 'PR';
// Corrected case to match directory structure
const REPORT_FILE = '.Jules/guard/report.json';

// --- Helpers ---

function log(msg, type = 'INFO') {
    const icons = { INFO: 'â„¹ï¸', SUCCESS: 'âœ…', WARN: 'âš ï¸', ERROR: 'âŒ', ACTION: 'ðŸ”§' };
    console.log(`${icons[type] || ''} [${new Date().toISOString()}] ${msg}`);
}

function run(cmd, args = [], options = {}) {
    const commandStr = `${cmd} ${args.join(' ')}`;
    // log(`Running: ${commandStr}`, 'INFO'); // verbose
    try {
        const result = spawnSync(cmd, args, { encoding: 'utf8', stdio: 'pipe', ...options });
        if (result.error) throw result.error;
        if (result.status !== 0 && !options.ignoreError) {
             throw new Error(`Command failed with status ${result.status}: ${commandStr}\nStderr: ${result.stderr}`);
        }
        return result.stdout ? result.stdout.trim() : '';
    } catch (e) {
        if (options.ignoreError) return null;
        throw new Error(`Command execution failed: ${commandStr}\n${e.message}`);
    }
}

function loadReport() {
    if (fs.existsSync(REPORT_FILE)) {
        try {
            return JSON.parse(fs.readFileSync(REPORT_FILE, 'utf8'));
        } catch (e) {
            log(`Failed to read existing report: ${e.message}`, 'WARN');
        }
    }
    return { timestamp: new Date().toISOString(), resolved: [], failures: [] };
}

function readReport() {
    try {
        if (fs.existsSync(REPORT_FILE)) {
            return JSON.parse(fs.readFileSync(REPORT_FILE, 'utf8'));
        }
    } catch (e) {}
    return { timestamp: new Date().toISOString(), resolved: [], failures: [] };
}

function writeReport(data) {
    try {
        fs.mkdirSync(path.dirname(REPORT_FILE), { recursive: true });
        let report = data;
        if (fs.existsSync(REPORT_FILE)) {
            try {
                const existing = JSON.parse(fs.readFileSync(REPORT_FILE, 'utf8'));
                // Merge arrays
                report = {
                    timestamp: data.timestamp,
                    resolved: [...(existing.resolved || []), ...data.resolved],
                    failures: [...(existing.failures || []), ...data.failures]
                };
            } catch (e) {}
        }
        fs.writeFileSync(REPORT_FILE, JSON.stringify(report, null, 2));
    } catch (e) {
        log(`Failed to write report: ${e.message}`, 'WARN');
    }
}

async function githubRequest(method, endpoint, body = null) {
    if (!GITHUB_TOKEN) {
        throw new Error('GITHUB_TOKEN is required for API access.');
    }
    return new Promise((resolve, reject) => {
        const options = {
            hostname: 'api.github.com',
            path: endpoint,
            method: method,
            headers: {
                'Authorization': `Bearer ${GITHUB_TOKEN}`,
                'User-Agent': 'Sentinel-Agent',
                'Accept': 'application/vnd.github+json',
                'X-GitHub-Api-Version': '2022-11-28'
            }
        };

        const req = https.request(options, (res) => {
            let data = '';
            res.on('data', (chunk) => data += chunk);
            res.on('end', () => {
                if (res.statusCode >= 200 && res.statusCode < 300) {
                    try {
                        resolve(JSON.parse(data));
                    } catch (e) {
                        resolve(data);
                    }
                } else {
                    reject(new Error(`GitHub API Error ${res.statusCode}: ${data}`));
                }
            });
        });

        req.on('error', (e) => reject(e));
        if (body) req.write(JSON.stringify(body));
        req.end();
    });
}

// --- Specific Fixers ---

function fixUnpinnedActions(fileContent) {
    let modified = false;
    let newContent = fileContent.replace(/uses:\s+([^\s]+)@(v[^\s]+)/g, (match, action, tag) => {
        if (tag.match(/^[0-9a-f]{40}$/)) return match;
        try {
            if (action.startsWith('./')) return match;
            const remote = `https://github.com/${action.split('/')[0]}/${action.split('/')[1]}`;
            // Use git ls-remote to find the SHA
            const output = run('git', ['ls-remote', remote, tag], { ignoreError: true });
            if (output) {
                const sha = output.split('\t')[0];
                if (sha && sha.match(/^[0-9a-f]{40}$/)) {
                    modified = true;
                    return `uses: ${action}@${sha} # ${tag}`;
                }
            }
        } catch (e) {
            log(`Failed to resolve SHA for ${action}@${tag}`, 'WARN');
        }
        return match;
    });
    return { modified, content: newContent };
}

function fixAstroDuplicates(content) {
    // Looks for Git conflict markers where HEAD is preserved.
    // Safety check: Only apply if conflict contains frontmatter fences '---'.
    // This targets the "Multiple Astro Component Definitions" scenario.
    // If it's a conflict deep in the HTML template without frontmatter, it's likely a semantic conflict.

    const conflictRegex = /<<<<<<< HEAD\n([\s\S]*?)\n=======\n[\s\S]*?>>>>>>> [^\n]*/g;
    let modified = false;
    let newContent = content;

    if (content.match(conflictRegex)) {
        newContent = content.replace(conflictRegex, (match, headContent) => {
            // Only resolve if it looks like a frontmatter/structure duplication
            if (match.includes('---')) {
                 modified = true;
                 return headContent;
            }
            return match; // Leave conflict markers if no frontmatter involved
        });
    }
    return { modified, content: newContent };
}

function fixDeadTodos(content) {
    // Regex for: return ...; // TODO ... (where TODO is unreachable)
    // Or just "return ...;" followed by "TODO" lines?
    // The instruction says: "If a TODO indicates incomplete code that is unreachable (e.g. following a return...)"
    // We'll look for `return ...;` followed by whitespace and a comment starting with TODO

    // Simple heuristic: return ...; // TODO ... on same line
    const inlineRegex = /(return\s+[^;]+;)\s*\/\/\s*TODO[^\n]*/g;
    let modified = false;
    let newContent = content.replace(inlineRegex, (match, ret) => {
        modified = true;
        return ret;
    });

    // TODO: Multiline unreachable code logic is complex with regex. Keeping it simple for now.

    return { modified, content: newContent };
}

function fixEnvTypes(content, filePath) {
    if (content.includes(': Env') || content.includes('<Env>')) {
        if (!content.includes('interface Env') && !content.includes('type Env') && !content.includes('import type { Env }')) {
             if (filePath.endsWith('.ts') || filePath.endsWith('.js')) {
                 const importStmt = "import type { Env } from '@cloudflare/workers-types';\n";
                 return { modified: true, content: importStmt + content };
             }
        }
    }
    return { modified: false, content };
}

function fixMissingImports(content, filePath) {
    const importRegex = /import\s+.*?\s+from\s+['"](\..*?)['"]/g;
    let modified = false;
    let match;

    while ((match = importRegex.exec(content)) !== null) {
        const importPath = match[1];
        try {
            const dir = path.dirname(filePath);
            const resolved = path.resolve(dir, importPath);
            const extensions = ['.ts', '.js', '.astro', '.tsx', '.jsx', '.json', ''];
            let exists = false;
            for (const ext of extensions) {
                if (fs.existsSync(resolved + ext) || (fs.existsSync(resolved) && fs.existsSync(path.join(resolved, 'index' + ext)))) {
                    exists = true;
                    break;
                }
            }

            if (!exists) {
                let newFile = resolved;
                if (!path.extname(newFile)) {
                    newFile += '.ts';
                }

                log(`Creating missing module: ${newFile}`, 'ACTION');
                fs.mkdirSync(path.dirname(newFile), { recursive: true });
                fs.writeFileSync(newFile, '// Sentinel: Generated stub for missing module\nexport {};\n');
                modified = true;
            }
        } catch (e) {}
    }
    return { modified, content };
}

function resolveMechanicalConflicts() {
    let resolvedFiles = [];

    // Check for conflicted files
    const conflictedFilesOutput = run('git', ['diff', '--name-only', '--diff-filter=U'], { ignoreError: true });
    const conflictedFiles = conflictedFilesOutput ? conflictedFilesOutput.split('\n').filter(Boolean) : [];

    // 1. Lockfile Conflicts
    // If pnpm-lock.yaml is conflicted, OR if we are resolving conflicts generally and want to be safe
    // The instructions say "Lockfile Conflicts: Remove...".
    // We'll do it if pnpm-lock.yaml is in the conflicted list or if package.json was conflicted.
    const lockfileConflicted = conflictedFiles.includes('pnpm-lock.yaml');

    // However, robust conflict resolution often benefits from regenerating lockfile anyway if merge failed.
    // We will do it if pnpm-lock.yaml exists and we are in this flow.
    if (fs.existsSync('pnpm-lock.yaml') && lockfileConflicted) {
        log('Regenerating lockfile...', 'ACTION');
        try { fs.unlinkSync('pnpm-lock.yaml'); } catch(e) {}
        run('rm', ['-rf', 'node_modules'], { ignoreError: true });
        run('pnpm', ['install'], { ignoreError: true });
        resolvedFiles.push('pnpm-lock.yaml');
    }

    // 2. File-level conflicts
    for (const file of conflictedFiles) {
        if (!fs.existsSync(file)) continue;
        if (file === 'pnpm-lock.yaml') continue; // Handled above

        let content = fs.readFileSync(file, 'utf8');
        let fileModified = false;

        // Astro Duplicates
        if (file.endsWith('.astro')) {
            const res = fixAstroDuplicates(content);
            if (res.modified) { content = res.content; fileModified = true; }
        }

        // Unpinned Actions
        if (file.startsWith('.github/workflows/')) {
            const res = fixUnpinnedActions(content);
            if (res.modified) { content = res.content; fileModified = true; }
        }

        // Missing Env Types
        const resEnv = fixEnvTypes(content, file);
        if (resEnv.modified) { content = resEnv.content; fileModified = true; }

        // Dead TODOs
        const resTodo = fixDeadTodos(content);
        if (resTodo.modified) { content = resTodo.content; fileModified = true; }

        // Missing Imports (side effect: creates files, AND potentially modifies content)
        const resImports = fixMissingImports(content, file);
        if (resImports.modified && resImports.content !== content) {
            content = resImports.content;
            fileModified = true;
        }

        if (fileModified) {
            fs.writeFileSync(file, content);
            resolvedFiles.push(file);
            run(`git add "${file}"`);
        }

        // Add file to stage even if not modified by us?
        // No, only if we resolved it. If we didn't touch it, it remains conflicted for manual review.
        // But fixMissingImports might not modify content but create a file.
        // If we fixed the file content (removed markers), we add it.
        // If we didn't remove markers, we shouldn't add it blindly?
        // fixAstroDuplicates removes markers.
        // If markers remain, `git add` will stage the conflict markers, which will fail build.
        // Sentinel strategy: Best effort.
        if (fileModified) {
            run('git', ['add', file]);
        }
    }

    // Always add pnpm-lock.yaml if we regenerated it
    if (resolvedFiles.includes('pnpm-lock.yaml')) {
        run('git', ['add', 'pnpm-lock.yaml']);
    }

    return resolvedFiles;
}

// --- Main Flows ---

async function fetchOpenPRs() {
    log('Fetching open PRs...');
    const prs = await githubRequest('GET', `/repos/${OWNER}/${REPO}/pulls?state=open`);
    if (!Array.isArray(prs)) return [];

    const candidates = [];
    for (const pr of prs) {
        // Need to fetch details to get mergeable_state
        const detailed = await githubRequest('GET', `/repos/${OWNER}/${REPO}/pulls/${pr.number}`);
        if (detailed.mergeable_state === 'dirty') {
            candidates.push(detailed);
        }
    }
    return candidates;
}

async function processPR(pr, reportObj) {
    if (pr.head.repo.full_name !== `${OWNER}/${REPO}`) {
        log(`Skipping fork PR #${pr.number} from ${pr.head.repo.full_name}`, 'WARN');
        return;
    }

    const branch = pr.head.ref;
    log(`Processing dirty PR #${pr.number} (${branch})...`, 'INFO');

    try {
        // 1. Checkout Branch
        run('git', ['fetch', 'origin', branch]);
        run('git', ['checkout', branch]);

        // 2. Rebase/Merge onto main
        try {
            run('git', ['fetch', 'origin', 'main']);
            run('git', ['rebase', 'origin/main']);
            // If rebase succeeds, we are good. But usually dirty PRs fail rebase.
        } catch (e) {
            log('Rebase failed, attempting manual merge resolution...', 'WARN');
            run('git', ['rebase', '--abort'], { ignoreError: true });
            try {
                // Fallback to merge to expose conflicts in working tree
                run('git', ['merge', 'origin/main']);
            } catch (mergeError) {
                // Merge failed, conflicts are in working tree. Proceed to fix.
            }
        }

        // 3. Resolve Mechanical Conflicts
        const fixedFiles = resolveMechanicalConflicts();

        if (fixedFiles.length > 0) {
            run('git', ['add', '.']); // Add all changes (including regenerated lockfile)
            run('git', ['commit', '-m', 'Sentinel: resolve merge conflicts and pin actions']);
        } else {
             // If we didn't fix anything, maybe there were no mechanical conflicts we could handle.
             // But we might have just rebased successfully?
             // If mergeable_state was dirty, rebase/merge should have triggered something.
        }

        // 4. Verify Build & Lint
        try {
            log('Verifying build...', 'INFO');
            run('pnpm', ['lint']);
            run('pnpm', ['build']);
        } catch (e) {
            log('Verification failed.', 'ERROR');
            // Revert changes? "If these fail, revert the automated changes"
            // We can just reset to origin/{branch}
            run('git', ['reset', '--hard', `origin/${branch}`]);

            await githubRequest('POST', `/repos/${OWNER}/${REPO}/issues/${pr.number}/labels`, { labels: ['needs-codex'] });
            await githubRequest('POST', `/repos/${OWNER}/${REPO}/issues/${pr.number}/comments`, {
                body: `ðŸ›¡ï¸ **Sentinel Report**\n\nAutomated resolution failed verification (Lint/Build). Handing off to Codex.`
            });
            reportObj.failures.push({ pr: pr.number, reason: 'Verification failed' });
            return;
        }

        // 5. Push the Resolved Branch
        log('Pushing changes...', 'ACTION');
        run('git', ['push', '--force-with-lease', 'origin', branch]);

        // 6. Document the Changes
        await githubRequest('POST', `/repos/${OWNER}/${REPO}/issues/${pr.number}/comments`, {
            body: `ðŸ›¡ï¸ **Sentinel Report**\n\nResolved merge conflicts and applied hygiene fixes.\n\n**Files touched:**\n${fixedFiles.map(f => `- ${f}`).join('\n')}`
        });
        reportObj.resolved.push({ pr: pr.number, files: fixedFiles });

    } catch (e) {
        log(`Failed to process ${branch}: ${e.message}`, 'ERROR');
        // Tag complex conflicts for Codex
        await githubRequest('POST', `/repos/${OWNER}/${REPO}/issues/${pr.number}/labels`, { labels: ['needs-codex'] });
        reportObj.failures.push({ pr: pr.number, reason: e.message });
    }
}

async function runSweep() {
    const report = loadReport();
    // Update timestamp for this run
    report.timestamp = new Date().toISOString();

    const dirtyPRs = await fetchOpenPRs();
    log(`Found ${dirtyPRs.length} dirty PRs.`);

    for (const pr of dirtyPRs) {
        await processPR(pr, report);
    }
    writeReport(report);
}

async function runPRMode() {
    const report = loadReport();
    report.timestamp = new Date().toISOString();

    const branch = process.env.GITHUB_HEAD_REF || run('git', ['rev-parse', '--abbrev-ref', 'HEAD']);
    // For local testing or if GITHUB_EVENT_PATH is missing
    let prNumber = null;
    if (process.env.GITHUB_EVENT_PATH) {
        try {
            const eventData = require(process.env.GITHUB_EVENT_PATH);
            prNumber = eventData.pull_request ? eventData.pull_request.number : null;
        } catch(e) {}
    }

    if (prNumber) {
        const pr = {
             number: prNumber,
             head: { ref: branch, repo: { full_name: `${OWNER}/${REPO}` } }
        };
        await processPR(pr, report);
    } else {
        log('No PR number found in environment.', 'WARN');
    }
    writeReport(report);
}

// --- Main ---
(async () => {
    try {
        if (MODE === 'SWEEP') {
            await runSweep();
        } else {
            await runPRMode();
        }
    } catch (e) {
        console.error(e);
        process.exit(1);
    }
})();
